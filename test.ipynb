{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying out simple sentiment analysis on tweets using the sentiment140 dataset. \n",
    "\n",
    "This is heavily based off of this [article](https://investigate.ai/investigating-sentiment-analysis/designing-your-own-sentiment-analysis-tool/) by investigate.ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files extracted to data\n"
     ]
    }
   ],
   "source": [
    "# extract the zip\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "# Path to the zip file\n",
    "zip_file_path = \"sentiment140.zip\"\n",
    "# Directory where you want to extract the files\n",
    "extract_dir = \"data\"\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "os.makedirs(extract_dir, exist_ok=True)\n",
    "\n",
    "# Open the zip file\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "    # Extract all the contents into the specified directory\n",
    "    zip_ref.extractall(extract_dir)\n",
    "\n",
    "print(f\"Files extracted to {extract_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset was downloaded from kaggle [here](https://www.kaggle.com/datasets/kazanova/sentiment140?resource=download)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by texting it... and might cry as a result  School today also. Blah!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Managed to save 50%  The rest go out of bounds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all. i'm mad. why am i here? because I can't see you all over there.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0           1                             2         3                4  \\\n",
       "0  0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY  _TheSpecialOne_   \n",
       "1  0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY    scotthamilton   \n",
       "2  0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY         mattycus   \n",
       "3  0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY          ElleCTF   \n",
       "4  0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY           Karoli   \n",
       "\n",
       "                                                                                                                     5  \n",
       "0  @switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D  \n",
       "1      is upset that he can't update his Facebook by texting it... and might cry as a result  School today also. Blah!  \n",
       "2                            @Kenichan I dived many times for the ball. Managed to save 50%  The rest go out of bounds  \n",
       "3                                                                      my whole body feels itchy and like its on fire   \n",
       "4      @nationwideclass no, it's not behaving at all. i'm mad. why am i here? because I can't see you all over there.   "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dataset\n",
    "\n",
    "df = pd.read_csv(\"data/sentiment140.csv\", encoding=\"ISO-8859-1\", header=None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>polarity</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by texting it... and might cry as a result  School today also. Blah!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Managed to save 50%  The rest go out of bounds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all. i'm mad. why am i here? because I can't see you all over there.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   polarity          id                          date      flag  \\\n",
       "0         0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n",
       "1         0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
       "2         0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
       "3         0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "4         0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "\n",
       "              user  \\\n",
       "0  _TheSpecialOne_   \n",
       "1    scotthamilton   \n",
       "2         mattycus   \n",
       "3          ElleCTF   \n",
       "4           Karoli   \n",
       "\n",
       "                                                                                                                  text  \n",
       "0  @switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D  \n",
       "1      is upset that he can't update his Facebook by texting it... and might cry as a result  School today also. Blah!  \n",
       "2                            @Kenichan I dived many times for the ball. Managed to save 50%  The rest go out of bounds  \n",
       "3                                                                      my whole body feels itchy and like its on fire   \n",
       "4      @nationwideclass no, it's not behaving at all. i'm mad. why am i here? because I can't see you all over there.   "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preprocessing\n",
    "# polarity = positive or negative (0 = neg, 4 = pos)\n",
    "# id = id of the tweet\n",
    "# date = date of the tweet\n",
    "# flag = query associated\n",
    "# user = user who tweeted the text\n",
    "# text = actual text of the tweet\n",
    "df.columns = ['polarity', 'id', 'date', 'flag', 'user', 'text']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>polarity</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>541200</th>\n",
       "      <td>0</td>\n",
       "      <td>2200003196</td>\n",
       "      <td>Tue Jun 16 18:18:12 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>LaLaLindsey0609</td>\n",
       "      <td>@chrishasboobs AHHH I HOPE YOUR OK!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>0</td>\n",
       "      <td>1467998485</td>\n",
       "      <td>Mon Apr 06 23:11:14 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>sexygrneyes</td>\n",
       "      <td>@misstoriblack cool , i have no tweet apps  for my razr 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766711</th>\n",
       "      <td>0</td>\n",
       "      <td>2300048954</td>\n",
       "      <td>Tue Jun 23 13:40:11 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>sammydearr</td>\n",
       "      <td>@TiannaChaos i know  just family drama. its lame.hey next time u hang out with kim n u guys like have a sleepover or whatever, ill call u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285055</th>\n",
       "      <td>0</td>\n",
       "      <td>1993474027</td>\n",
       "      <td>Mon Jun 01 10:26:07 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Lamb_Leanne</td>\n",
       "      <td>School email won't open  and I have geography stuff on there to revise! *Stupid School* :'(</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705995</th>\n",
       "      <td>0</td>\n",
       "      <td>2256550904</td>\n",
       "      <td>Sat Jun 20 12:56:51 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>yogicerdito</td>\n",
       "      <td>upper airways problem</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        polarity          id                          date      flag  \\\n",
       "541200         0  2200003196  Tue Jun 16 18:18:12 PDT 2009  NO_QUERY   \n",
       "750            0  1467998485  Mon Apr 06 23:11:14 PDT 2009  NO_QUERY   \n",
       "766711         0  2300048954  Tue Jun 23 13:40:11 PDT 2009  NO_QUERY   \n",
       "285055         0  1993474027  Mon Jun 01 10:26:07 PDT 2009  NO_QUERY   \n",
       "705995         0  2256550904  Sat Jun 20 12:56:51 PDT 2009  NO_QUERY   \n",
       "\n",
       "                   user  \\\n",
       "541200  LaLaLindsey0609   \n",
       "750         sexygrneyes   \n",
       "766711       sammydearr   \n",
       "285055      Lamb_Leanne   \n",
       "705995      yogicerdito   \n",
       "\n",
       "                                                                                                                                             text  \n",
       "541200                                                                                                     @chrishasboobs AHHH I HOPE YOUR OK!!!   \n",
       "750                                                                                     @misstoriblack cool , i have no tweet apps  for my razr 2  \n",
       "766711  @TiannaChaos i know  just family drama. its lame.hey next time u hang out with kim n u guys like have a sleepover or whatever, ill call u  \n",
       "285055                                                School email won't open  and I have geography stuff on there to revise! *Stupid School* :'(  \n",
       "705995                                                                                                                     upper airways problem   "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cut it down, take 50000 random samples from the dataset (skipped alr done)\n",
    "df = df.sample(n=50000, random_state=42)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 6)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of         polarity          id                          date      flag  \\\n",
       "541200         0  2200003196  Tue Jun 16 18:18:12 PDT 2009  NO_QUERY   \n",
       "750            0  1467998485  Mon Apr 06 23:11:14 PDT 2009  NO_QUERY   \n",
       "766711         0  2300048954  Tue Jun 23 13:40:11 PDT 2009  NO_QUERY   \n",
       "285055         0  1993474027  Mon Jun 01 10:26:07 PDT 2009  NO_QUERY   \n",
       "705995         0  2256550904  Sat Jun 20 12:56:51 PDT 2009  NO_QUERY   \n",
       "...          ...         ...                           ...       ...   \n",
       "199266         0  1971396270  Sat May 30 07:00:39 PDT 2009  NO_QUERY   \n",
       "210814         0  1974331559  Sat May 30 12:54:50 PDT 2009  NO_QUERY   \n",
       "180674         0  1966611316  Fri May 29 18:04:55 PDT 2009  NO_QUERY   \n",
       "364859         0  2048348064  Fri Jun 05 15:03:22 PDT 2009  NO_QUERY   \n",
       "172400         0  1963565183  Fri May 29 12:55:00 PDT 2009  NO_QUERY   \n",
       "\n",
       "                   user  \\\n",
       "541200  LaLaLindsey0609   \n",
       "750         sexygrneyes   \n",
       "766711       sammydearr   \n",
       "285055      Lamb_Leanne   \n",
       "705995      yogicerdito   \n",
       "...                 ...   \n",
       "199266     EllenAshleee   \n",
       "210814       leftynerak   \n",
       "180674         AnnHeart   \n",
       "364859       gracegorms   \n",
       "172400      deiapoynter   \n",
       "\n",
       "                                                                                                                                             text  \n",
       "541200                                                                                                     @chrishasboobs AHHH I HOPE YOUR OK!!!   \n",
       "750                                                                                     @misstoriblack cool , i have no tweet apps  for my razr 2  \n",
       "766711  @TiannaChaos i know  just family drama. its lame.hey next time u hang out with kim n u guys like have a sleepover or whatever, ill call u  \n",
       "285055                                                School email won't open  and I have geography stuff on there to revise! *Stupid School* :'(  \n",
       "705995                                                                                                                     upper airways problem   \n",
       "...                                                                                                                                           ...  \n",
       "199266                                                                                             On the way home. Tired. I don't wanna babysit   \n",
       "210814                               Well that was ten sneezes in a row. My allergies are not making my day easy. Still no air through the nose.   \n",
       "180674                                                                               can't go out tonight car is acting funny   wat shall i do???  \n",
       "364859                                                                                                                              Headacheeeee   \n",
       "172400                                                       @tommcfly you and the guys should come down here, we are fucking freezing out here!   \n",
       "\n",
       "[50000 rows x 6 columns]>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "polarity\n",
       "4    25014\n",
       "0    24986\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# counting the totals of each possible value in polarity (how many postive compared to negative tweets)\n",
    "df.polarity.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>15</th>\n",
       "      <th>1st</th>\n",
       "      <th>20</th>\n",
       "      <th>2day</th>\n",
       "      <th>30</th>\n",
       "      <th>able</th>\n",
       "      <th>...</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>yet</th>\n",
       "      <th>yo</th>\n",
       "      <th>you</th>\n",
       "      <th>your</th>\n",
       "      <th>yours</th>\n",
       "      <th>yourself</th>\n",
       "      <th>youtube</th>\n",
       "      <th>yummy</th>\n",
       "      <th>yup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.373036</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    10  100   11   12   15  1st   20  2day   30  able  ...  yesterday  yet  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0   0.0  ...        0.0  0.0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0   0.0  ...        0.0  0.0   \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0   0.0  ...        0.0  0.0   \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0   0.0  ...        0.0  0.0   \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0   0.0  ...        0.0  0.0   \n",
       "\n",
       "    yo  you      your  yours  yourself  youtube  yummy  yup  \n",
       "0  0.0  0.0  0.373036    0.0       0.0      0.0    0.0  0.0  \n",
       "1  0.0  0.0  0.000000    0.0       0.0      0.0    0.0  0.0  \n",
       "2  0.0  0.0  0.000000    0.0       0.0      0.0    0.0  0.0  \n",
       "3  0.0  0.0  0.000000    0.0       0.0      0.0    0.0  0.0  \n",
       "4  0.0  0.0  0.000000    0.0       0.0      0.0    0.0  0.0  \n",
       "\n",
       "[5 rows x 1000 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vectorizing the tweets\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=1000)\n",
    "vectors = vectorizer.fit_transform(df.text)\n",
    "words_df = pd.DataFrame(vectors.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "words_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# storing the features (X) and labels (y)'\n",
    "X = words_df\n",
    "y = df.polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing all algorithms\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 16.6 s\n",
      "Wall time: 5.86 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-11 {color: black;background-color: white;}#sk-container-id-11 pre{padding: 0;}#sk-container-id-11 div.sk-toggleable {background-color: white;}#sk-container-id-11 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-11 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-11 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-11 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-11 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-11 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-11 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-11 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-11 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-11 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-11 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-11 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-11 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-11 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-11 div.sk-item {position: relative;z-index: 1;}#sk-container-id-11 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-11 div.sk-item::before, #sk-container-id-11 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-11 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-11 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-11 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-11 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-11 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-11 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-11 div.sk-label-container {text-align: center;}#sk-container-id-11 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-11 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-11\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=1000000000.0, max_iter=1000, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" checked><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=1000000000.0, max_iter=1000, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=1000000000.0, max_iter=1000, random_state=42)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# logistic reg\n",
    "logreg = LogisticRegression(C=1e9, solver='lbfgs', max_iter=1000, random_state=42)\n",
    "logreg.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 20.8 s\n",
      "Wall time: 1min 1s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-12 {color: black;background-color: white;}#sk-container-id-12 pre{padding: 0;}#sk-container-id-12 div.sk-toggleable {background-color: white;}#sk-container-id-12 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-12 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-12 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-12 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-12 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-12 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-12 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-12 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-12 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-12 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-12 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-12 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-12 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-12 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-12 div.sk-item {position: relative;z-index: 1;}#sk-container-id-12 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-12 div.sk-item::before, #sk-container-id-12 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-12 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-12 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-12 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-12 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-12 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-12 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-12 div.sk-label-container {text-align: center;}#sk-container-id-12 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-12 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-12\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(n_estimators=50, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" checked><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_estimators=50, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(n_estimators=50, random_state=42)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# random forest\n",
    "rf = RandomForestClassifier(n_estimators=50, random_state=42)\n",
    "rf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 250 ms\n",
      "Wall time: 519 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-13 {color: black;background-color: white;}#sk-container-id-13 pre{padding: 0;}#sk-container-id-13 div.sk-toggleable {background-color: white;}#sk-container-id-13 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-13 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-13 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-13 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-13 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-13 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-13 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-13 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-13 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-13 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-13 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-13 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-13 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-13 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-13 div.sk-item {position: relative;z-index: 1;}#sk-container-id-13 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-13 div.sk-item::before, #sk-container-id-13 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-13 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-13 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-13 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-13 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-13 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-13 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-13 div.sk-label-container {text-align: center;}#sk-container-id-13 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-13 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-13\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearSVC(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" checked><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearSVC</label><div class=\"sk-toggleable__content\"><pre>LinearSVC(random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearSVC(random_state=42)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# svc\n",
    "svc = LinearSVC(random_state=42)\n",
    "svc.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "MultinomialNB.__init__() got an unexpected keyword argument 'random_state'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32m<timed exec>:2\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: MultinomialNB.__init__() got an unexpected keyword argument 'random_state'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# naive bayes classifier\n",
    "bayes = MultinomialNB(random_state=42)\n",
    "bayes.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The new marvel movie is kinda mid.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hate the new keyboard, not worth it at all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not sure how i feel about soggy toast in the morning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Feeling indifferent about the weather today, it's just... meh.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>did you see the new joker movie? it was okay.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>my figure arrived late and the head broke offff what the heck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>i cant stop watching dunmeshi god it's so addicting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>the concert was ok but coulda been better</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>people have to stop doomscrolling its so tiring seeing all the bad stuff on here</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>idk why people can't just fucking be normal is it that hard to be nice????</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>won't lie sote is good but some areas are just... empty. like what...?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                             content\n",
       "0                                                 The new marvel movie is kinda mid.\n",
       "1                                         hate the new keyboard, not worth it at all\n",
       "2                               Not sure how i feel about soggy toast in the morning\n",
       "3                     Feeling indifferent about the weather today, it's just... meh.\n",
       "4                                      did you see the new joker movie? it was okay.\n",
       "5                      my figure arrived late and the head broke offff what the heck\n",
       "6                                i cant stop watching dunmeshi god it's so addicting\n",
       "7                                          the concert was ok but coulda been better\n",
       "8   people have to stop doomscrolling its so tiring seeing all the bad stuff on here\n",
       "9         idk why people can't just fucking be normal is it that hard to be nice????\n",
       "10            won't lie sote is good but some areas are just... empty. like what...?"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option(\"display.max_colwidth\", 200)\n",
    "\n",
    "test = pd.DataFrame({'content': [\n",
    "    \"The new marvel movie is kinda mid.\",\n",
    "    \"hate the new keyboard, not worth it at all\",\n",
    "    \"Not sure how i feel about soggy toast in the morning\",\n",
    "    \"Feeling indifferent about the weather today, it's just... meh.\",\n",
    "    \"did you see the new joker movie? it was okay.\",\n",
    "    \"my figure arrived late and the head broke offff what the heck\",\n",
    "    \"i cant stop watching dunmeshi god it's so addicting\",\n",
    "    \"the concert was ok but coulda been better\",\n",
    "    \"people have to stop doomscrolling its so tiring seeing all the bad stuff on here\",\n",
    "    \"idk why people can't just fucking be normal is it that hard to be nice????\",\n",
    "    \"won't lie sote is good but some areas are just... empty. like what...?\",\n",
    "]})\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['10' '100' '11' '12' '15' '1st' '20' '2day' '30' 'able' 'about'\n",
      " 'absolutely' 'account' 'actually' 'add' 'afraid' 'after' 'afternoon'\n",
      " 'again' 'ago' 'agree' 'ah' 'ahead' 'ahh' 'ahhh' 'aint' 'air' 'airport'\n",
      " 'album' 'all' 'almost' 'alone' 'along' 'already' 'alright' 'also'\n",
      " 'although' 'always' 'am' 'amazing' 'amp' 'an' 'and' 'annoying' 'another'\n",
      " 'answer' 'any' 'anymore' 'anyone' 'anything' 'anyway' 'apparently'\n",
      " 'apple' 'are' 'aren' 'around' 'art' 'as' 'ask' 'asleep' 'ass' 'at' 'ate'\n",
      " 'aw' 'awake' 'awards' 'away' 'awesome' 'aww' 'awww' 'baby' 'back' 'bad'\n",
      " 'band' 'bbq' 'bday' 'be' 'beach' 'beat' 'beautiful' 'because' 'bed'\n",
      " 'been' 'beer' 'before' 'behind' 'being' 'believe' 'best' 'bet' 'better'\n",
      " 'big' 'bike' 'birthday' 'bit' 'black' 'blip' 'blog' 'blood' 'blue' 'body'\n",
      " 'boo' 'book' 'books' 'bored' 'boring' 'both' 'bought' 'bout' 'box' 'boy'\n",
      " 'boyfriend' 'boys' 'break' 'breakfast' 'bring' 'bro' 'broke' 'broken'\n",
      " 'brother' 'brothers' 'btw' 'bus' 'busy' 'but' 'buy' 'by' 'bye' 'cake'\n",
      " 'call' 'called' 'came' 'camera' 'can' 'cannot' 'cant' 'car' 'card' 'care'\n",
      " 'case' 'cat' 'catch' 'cause' 'cd' 'chance' 'change' 'changed' 'chat'\n",
      " 'check' 'chicken' 'chillin' 'chocolate' 'church' 'city' 'class' 'clean'\n",
      " 'cleaning' 'close' 'clothes' 'club' 'coffee' 'cold' 'college' 'com'\n",
      " 'come' 'comes' 'coming' 'comment' 'computer' 'concert' 'congrats' 'cool'\n",
      " 'cos' 'could' 'couldn' 'couple' 'course' 'crap' 'crazy' 'cream' 'cry'\n",
      " 'crying' 'cut' 'cute' 'cuz' 'da' 'dad' 'damn' 'dance' 'date' 'david'\n",
      " 'day' 'days' 'ddlovato' 'de' 'dead' 'dear' 'death' 'decided' 'definitely'\n",
      " 'did' 'didn' 'didnt' 'die' 'died' 'different' 'dinner' 'dm' 'do' 'does'\n",
      " 'doesn' 'doesnt' 'dog' 'doing' 'don' 'done' 'dont' 'door' 'down'\n",
      " 'download' 'dream' 'dreams' 'dress' 'drink' 'drinking' 'drive' 'driving'\n",
      " 'dude' 'due' 'during' 'each' 'earlier' 'early' 'easy' 'eat' 'eating' 'eh'\n",
      " 'either' 'else' 'em' 'email' 'end' 'english' 'enjoy' 'enjoyed' 'enjoying'\n",
      " 'enough' 'especially' 'even' 'evening' 'ever' 'every' 'everyone'\n",
      " 'everything' 'exactly' 'exam' 'exams' 'except' 'excited' 'exciting' 'eye'\n",
      " 'eyes' 'face' 'facebook' 'fact' 'fail' 'fair' 'fall' 'family' 'fan'\n",
      " 'fans' 'far' 'fast' 'fat' 'favorite' 'fb' 'feel' 'feeling' 'feels' 'feet'\n",
      " 'fell' 'felt' 'few' 'ff' 'figure' 'film' 'final' 'finally' 'finals'\n",
      " 'find' 'fine' 'finish' 'finished' 'first' 'fix' 'fixed' 'flight' 'flu'\n",
      " 'fm' 'follow' 'followers' 'followfriday' 'following' 'food' 'for'\n",
      " 'forever' 'forget' 'forgot' 'forward' 'found' 'free' 'french' 'friday'\n",
      " 'friend' 'friends' 'from' 'fuck' 'fucking' 'full' 'fun' 'funny' 'game'\n",
      " 'games' 'garden' 'gave' 'gay' 'get' 'gets' 'gettin' 'getting' 'girl'\n",
      " 'girls' 'give' 'giving' 'glad' 'go' 'god' 'goes' 'goin' 'going' 'gone'\n",
      " 'gonna' 'good' 'goodbye' 'goodnight' 'google' 'gorgeous' 'got' 'gotta'\n",
      " 'graduation' 'great' 'green' 'gt' 'guess' 'guy' 'guys' 'gym' 'ha' 'had'\n",
      " 'haha' 'hahaha' 'hair' 'half' 'hand' 'hang' 'hanging' 'happen' 'happened'\n",
      " 'happens' 'happy' 'hard' 'has' 'hate' 'hates' 'have' 'haven' 'havent'\n",
      " 'having' 'he' 'head' 'headache' 'heading' 'hear' 'heard' 'heart' 'hehe'\n",
      " 'hell' 'hello' 'help' 'her' 'here' 'hey' 'hi' 'high' 'him' 'his' 'hit'\n",
      " 'hmm' 'hmmm' 'holiday' 'home' 'homework' 'hope' 'hopefully' 'hoping'\n",
      " 'horrible' 'hospital' 'hot' 'hotel' 'hour' 'hours' 'house' 'how' 'http'\n",
      " 'hubby' 'hug' 'huge' 'hugs' 'huh' 'hungry' 'hurt' 'hurts' 'ice' 'idea'\n",
      " 'idk' 'if' 'ill' 'im' 'in' 'inside' 'instead' 'interesting' 'internet'\n",
      " 'into' 'iphone' 'ipod' 'is' 'isn' 'isnt' 'it' 'its' 'ive' 'jealous' 'job'\n",
      " 'join' 'jonas' 'jonasbrothers' 'june' 'just' 'keep' 'keeps' 'kid' 'kids'\n",
      " 'kind' 'kinda' 'knew' 'know' 'knows' 'la' 'lady' 'lakers' 'lame' 'laptop'\n",
      " 'last' 'late' 'lately' 'later' 'laugh' 'laying' 'lazy' 'learn' 'least'\n",
      " 'leave' 'leaving' 'left' 'less' 'let' 'lets' 'life' 'light' 'like'\n",
      " 'liked' 'lil' 'line' 'link' 'list' 'listen' 'listening' 'little' 'live'\n",
      " 'living' 'll' 'lmao' 'lol' 'london' 'lonely' 'long' 'longer' 'look'\n",
      " 'looked' 'looking' 'looks' 'lose' 'lost' 'lot' 'lots' 'love' 'loved'\n",
      " 'lovely' 'loves' 'loving' 'lt' 'luck' 'lucky' 'lunch' 'luv' 'ly' 'ma'\n",
      " 'mac' 'mad' 'made' 'magic' 'make' 'makes' 'making' 'man' 'many' 'maths'\n",
      " 'may' 'maybe' 'me' 'mean' 'means' 'meant' 'meet' 'meeting' 'message'\n",
      " 'met' 'might' 'miley' 'mileycyrus' 'mind' 'mine' 'minutes' 'miss'\n",
      " 'missed' 'missing' 'mom' 'moment' 'monday' 'money' 'month' 'months'\n",
      " 'mood' 'moon' 'more' 'morning' 'most' 'mother' 'move' 'movie' 'movies'\n",
      " 'moving' 'mr' 'mtv' 'much' 'mum' 'music' 'must' 'my' 'myloc' 'myself'\n",
      " 'myspace' 'name' 'nap' 'near' 'need' 'needed' 'needs' 'never' 'new'\n",
      " 'news' 'next' 'nice' 'night' 'nights' 'nite' 'no' 'nope' 'not' 'nothing'\n",
      " 'now' 'number' 'of' 'off' 'office' 'officially' 'oh' 'ok' 'okay' 'old'\n",
      " 'omg' 'on' 'once' 'one' 'ones' 'online' 'only' 'open' 'or' 'order'\n",
      " 'other' 'ouch' 'our' 'out' 'outside' 'over' 'own' 'packing' 'page' 'pain'\n",
      " 'paper' 'parents' 'park' 'part' 'party' 'past' 'pay' 'peace' 'people'\n",
      " 'perfect' 'person' 'phone' 'photo' 'photos' 'pic' 'pick' 'pics' 'picture'\n",
      " 'pictures' 'pissed' 'pizza' 'place' 'plan' 'plans' 'play' 'played'\n",
      " 'playing' 'please' 'plurk' 'plus' 'point' 'pool' 'poor' 'post' 'posted'\n",
      " 'power' 'ppl' 'pretty' 'probably' 'problem' 'project' 'proud' 'put'\n",
      " 'quite' 'quot' 'radio' 'rain' 'raining' 'rainy' 'rather' 're' 'read'\n",
      " 'reading' 'ready' 'real' 'realized' 'really' 'reason' 'red' 'remember'\n",
      " 'reply' 'rest' 'ride' 'right' 'road' 'rock' 'room' 'round' 'run'\n",
      " 'running' 'sad' 'sadly' 'safe' 'said' 'same' 'sat' 'saturday' 'save'\n",
      " 'saw' 'say' 'saying' 'says' 'scared' 'school' 'season' 'second' 'see'\n",
      " 'seeing' 'seem' 'seems' 'seen' 'send' 'sent' 'seriously' 'set' 'shall'\n",
      " 'shame' 'she' 'shirt' 'shit' 'shoes' 'shop' 'shopping' 'short' 'should'\n",
      " 'show' 'shower' 'shows' 'sick' 'side' 'sigh' 'sign' 'sims' 'since' 'sing'\n",
      " 'sister' 'site' 'sitting' 'sleep' 'sleeping' 'sleepy' 'slept' 'slow'\n",
      " 'small' 'smile' 'so' 'sold' 'some' 'someone' 'something' 'sometimes'\n",
      " 'son' 'song' 'songs' 'soo' 'soon' 'sooo' 'soooo' 'sore' 'sorry' 'sound'\n",
      " 'sounds' 'special' 'spend' 'spent' 'star' 'start' 'started' 'starting'\n",
      " 'starts' 'stay' 'still' 'stomach' 'stop' 'store' 'story' 'stuck' 'study'\n",
      " 'studying' 'stuff' 'stupid' 'such' 'suck' 'sucks' 'summer' 'sun' 'sunday'\n",
      " 'sunny' 'sunshine' 'super' 'support' 'supposed' 'sure' 'sweet' 'take'\n",
      " 'taken' 'taking' 'talk' 'talking' 'tea' 'team' 'tell' 'test' 'text'\n",
      " 'than' 'thank' 'thanks' 'that' 'thats' 'the' 'their' 'them' 'then'\n",
      " 'there' 'these' 'they' 'thing' 'things' 'think' 'thinking' 'thinks'\n",
      " 'this' 'tho' 'those' 'though' 'thought' 'three' 'throat' 'through'\n",
      " 'thursday' 'thx' 'tickets' 'til' 'till' 'time' 'times' 'tinyurl' 'tired'\n",
      " 'to' 'today' 'together' 'told' 'tom' 'tommcfly' 'tomorrow' 'tonight'\n",
      " 'too' 'took' 'top' 'totally' 'touch' 'tour' 'town' 'traffic' 'train'\n",
      " 'tried' 'trip' 'true' 'try' 'trying' 'tuesday' 'tummy' 'turn' 'turned'\n",
      " 'tv' 'tweet' 'tweeting' 'tweets' 'twilight' 'twitpic' 'twitter' 'two'\n",
      " 'type' 'ugh' 'uk' 'under' 'understand' 'unfortunately' 'until' 'up'\n",
      " 'update' 'updates' 'upset' 'ur' 'us' 'use' 'used' 'using' 'vacation' 've'\n",
      " 'version' 'very' 'via' 'video' 'videos' 'visit' 'voice' 'vote' 'wait'\n",
      " 'waiting' 'wake' 'waking' 'walk' 'walking' 'wanna' 'want' 'wanted'\n",
      " 'wants' 'warm' 'was' 'wasn' 'watch' 'watched' 'watching' 'water' 'way'\n",
      " 'we' 'wear' 'weather' 'website' 'wedding' 'wednesday' 'week' 'weekend'\n",
      " 'weeks' 'weird' 'welcome' 'well' 'went' 'were' 'what' 'whatever' 'whats'\n",
      " 'when' 'where' 'which' 'while' 'white' 'who' 'whole' 'why' 'wife' 'will'\n",
      " 'win' 'wine' 'wish' 'wishes' 'wishing' 'with' 'without' 'woke' 'won'\n",
      " 'wonder' 'wonderful' 'wondering' 'wont' 'woo' 'word' 'words' 'work'\n",
      " 'worked' 'working' 'works' 'world' 'worried' 'worry' 'worse' 'worst'\n",
      " 'worth' 'would' 'wouldn' 'wow' 'write' 'writing' 'wrong' 'wtf' 'www' 'xd'\n",
      " 'xoxo' 'xx' 'xxx' 'ya' 'yay' 'yea' 'yeah' 'year' 'years' 'yep' 'yes'\n",
      " 'yesterday' 'yet' 'yo' 'you' 'your' 'yours' 'yourself' 'youtube' 'yummy'\n",
      " 'yup']\n"
     ]
    }
   ],
   "source": [
    "print(vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>15</th>\n",
       "      <th>1st</th>\n",
       "      <th>20</th>\n",
       "      <th>2day</th>\n",
       "      <th>30</th>\n",
       "      <th>able</th>\n",
       "      <th>...</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>yet</th>\n",
       "      <th>yo</th>\n",
       "      <th>you</th>\n",
       "      <th>your</th>\n",
       "      <th>yours</th>\n",
       "      <th>yourself</th>\n",
       "      <th>youtube</th>\n",
       "      <th>yummy</th>\n",
       "      <th>yup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.214724</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    10  100   11   12   15  1st   20  2day   30  able  ...  yesterday  yet  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0   0.0  ...        0.0  0.0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0   0.0  ...        0.0  0.0   \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0   0.0  ...        0.0  0.0   \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0   0.0  ...        0.0  0.0   \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0   0.0  ...        0.0  0.0   \n",
       "\n",
       "    yo       you  your  yours  yourself  youtube  yummy  yup  \n",
       "0  0.0  0.000000   0.0    0.0       0.0      0.0    0.0  0.0  \n",
       "1  0.0  0.000000   0.0    0.0       0.0      0.0    0.0  0.0  \n",
       "2  0.0  0.000000   0.0    0.0       0.0      0.0    0.0  0.0  \n",
       "3  0.0  0.000000   0.0    0.0       0.0      0.0    0.0  0.0  \n",
       "4  0.0  0.214724   0.0    0.0       0.0      0.0    0.0  0.0  \n",
       "\n",
       "[5 rows x 1000 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_vectors = vectorizer.transform(test.content)\n",
    "test_words_df = pd.DataFrame(test_vectors.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "test_words_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 1000)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_words_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model predictions\n",
    "\n",
    "# log reg predictions + probabilities\n",
    "test['pred_logreg'] = logreg.predict(test_words_df)\n",
    "test['pred_logreg_proba'] = logreg.predict_proba(test_words_df)[:,1]\n",
    "\n",
    "# random forest predictions + probabilities\n",
    "test['pred_forest'] = rf.predict(test_words_df)\n",
    "test['pred_forest_proba'] = rf.predict_proba(test_words_df)[:,1]\n",
    "\n",
    "# svc predictions\n",
    "test['pred_svc'] = svc.predict(test_words_df)\n",
    "\n",
    "# naive bayes predictions + probabilities\n",
    "test['pred_bayes'] = bayes.predict(test_words_df)\n",
    "test['pred_bayes_proba'] = bayes.predict_proba(test_words_df)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>pred_logreg</th>\n",
       "      <th>pred_logreg_proba</th>\n",
       "      <th>pred_forest</th>\n",
       "      <th>pred_forest_proba</th>\n",
       "      <th>pred_svc</th>\n",
       "      <th>pred_bayes</th>\n",
       "      <th>pred_bayes_proba</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The new marvel movie is kinda mid.</td>\n",
       "      <td>4</td>\n",
       "      <td>0.879679</td>\n",
       "      <td>4</td>\n",
       "      <td>0.98</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.655362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hate the new keyboard, not worth it at all</td>\n",
       "      <td>0</td>\n",
       "      <td>0.146346</td>\n",
       "      <td>0</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.349759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not sure how i feel about soggy toast in the morning</td>\n",
       "      <td>0</td>\n",
       "      <td>0.306354</td>\n",
       "      <td>0</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.510399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Feeling indifferent about the weather today, it's just... meh.</td>\n",
       "      <td>0</td>\n",
       "      <td>0.235788</td>\n",
       "      <td>0</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.365722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>did you see the new joker movie? it was okay.</td>\n",
       "      <td>4</td>\n",
       "      <td>0.938208</td>\n",
       "      <td>4</td>\n",
       "      <td>0.93</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.767261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>my figure arrived late and the head broke offff what the heck</td>\n",
       "      <td>0</td>\n",
       "      <td>0.159757</td>\n",
       "      <td>0</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.227229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>i cant stop watching dunmeshi god it's so addicting</td>\n",
       "      <td>4</td>\n",
       "      <td>0.504499</td>\n",
       "      <td>0</td>\n",
       "      <td>0.40</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.492799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>the concert was ok but coulda been better</td>\n",
       "      <td>0</td>\n",
       "      <td>0.432442</td>\n",
       "      <td>0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.445777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>people have to stop doomscrolling its so tiring seeing all the bad stuff on here</td>\n",
       "      <td>0</td>\n",
       "      <td>0.212730</td>\n",
       "      <td>0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.397773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>idk why people can't just fucking be normal is it that hard to be nice????</td>\n",
       "      <td>0</td>\n",
       "      <td>0.136796</td>\n",
       "      <td>0</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.338457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>won't lie sote is good but some areas are just... empty. like what...?</td>\n",
       "      <td>4</td>\n",
       "      <td>0.627710</td>\n",
       "      <td>4</td>\n",
       "      <td>0.58</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.547307</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                             content  \\\n",
       "0                                                 The new marvel movie is kinda mid.   \n",
       "1                                         hate the new keyboard, not worth it at all   \n",
       "2                               Not sure how i feel about soggy toast in the morning   \n",
       "3                     Feeling indifferent about the weather today, it's just... meh.   \n",
       "4                                      did you see the new joker movie? it was okay.   \n",
       "5                      my figure arrived late and the head broke offff what the heck   \n",
       "6                                i cant stop watching dunmeshi god it's so addicting   \n",
       "7                                          the concert was ok but coulda been better   \n",
       "8   people have to stop doomscrolling its so tiring seeing all the bad stuff on here   \n",
       "9         idk why people can't just fucking be normal is it that hard to be nice????   \n",
       "10            won't lie sote is good but some areas are just... empty. like what...?   \n",
       "\n",
       "    pred_logreg  pred_logreg_proba  pred_forest  pred_forest_proba  pred_svc  \\\n",
       "0             4           0.879679            4               0.98         4   \n",
       "1             0           0.146346            0               0.16         0   \n",
       "2             0           0.306354            0               0.34         0   \n",
       "3             0           0.235788            0               0.28         0   \n",
       "4             4           0.938208            4               0.93         4   \n",
       "5             0           0.159757            0               0.22         0   \n",
       "6             4           0.504499            0               0.40         4   \n",
       "7             0           0.432442            0               0.32         0   \n",
       "8             0           0.212730            0               0.20         0   \n",
       "9             0           0.136796            0               0.44         0   \n",
       "10            4           0.627710            4               0.58         4   \n",
       "\n",
       "    pred_bayes  pred_bayes_proba  \n",
       "0            4          0.655362  \n",
       "1            0          0.349759  \n",
       "2            4          0.510399  \n",
       "3            0          0.365722  \n",
       "4            4          0.767261  \n",
       "5            0          0.227229  \n",
       "6            0          0.492799  \n",
       "7            0          0.445777  \n",
       "8            0          0.397773  \n",
       "9            0          0.338457  \n",
       "10           4          0.547307  "
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using train and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training logistic regression...\n",
      "Training random forest...\n",
      "Training svc...\n",
      "Training naive bayes...\n",
      "CPU times: total: 25.1 s\n",
      "Wall time: 41.3 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-14 {color: black;background-color: white;}#sk-container-id-14 pre{padding: 0;}#sk-container-id-14 div.sk-toggleable {background-color: white;}#sk-container-id-14 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-14 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-14 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-14 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-14 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-14 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-14 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-14 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-14 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-14 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-14 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-14 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-14 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-14 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-14 div.sk-item {position: relative;z-index: 1;}#sk-container-id-14 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-14 div.sk-item::before, #sk-container-id-14 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-14 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-14 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-14 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-14 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-14 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-14 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-14 div.sk-label-container {text-align: center;}#sk-container-id-14 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-14 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-14\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" checked><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "print(\"Training logistic regression...\")\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "print(\"Training random forest...\")\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Training svc...\")\n",
    "svc.fit(X_train, y_train)\n",
    "\n",
    "print(\"Training naive bayes...\")\n",
    "bayes.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual values\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted negative</th>\n",
       "      <th>Predicted positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Is negative</th>\n",
       "      <td>4628</td>\n",
       "      <td>1605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Is positive</th>\n",
       "      <td>1446</td>\n",
       "      <td>4821</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Predicted negative  Predicted positive\n",
       "Is negative                4628                1605\n",
       "Is positive                1446                4821"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking accuracy\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "# logreg\n",
    "y_true = y_test\n",
    "y_pred = logreg.predict(X_test)\n",
    "matrix = confusion_matrix(y_true, y_pred)\n",
    "logreg_acc = accuracy_score(y_true, y_pred)\n",
    "\n",
    "# value count\n",
    "print(\"Actual values\")\n",
    "label_names = pd.Series(['negative', 'positive'])\n",
    "pd.DataFrame(matrix,\n",
    "     columns='Predicted ' + label_names,\n",
    "     index='Is ' + label_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted negative</th>\n",
       "      <th>Predicted positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Is negative</th>\n",
       "      <td>0.742500</td>\n",
       "      <td>0.257500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Is positive</th>\n",
       "      <td>0.230732</td>\n",
       "      <td>0.769268</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Predicted negative  Predicted positive\n",
       "Is negative            0.742500            0.257500\n",
       "Is positive            0.230732            0.769268"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# percentage\n",
    "print(\"Percentage\")\n",
    "label_names = pd.Series(['negative', 'positive'])\n",
    "pd.DataFrame(matrix,\n",
    "     columns='Predicted ' + label_names,\n",
    "     index='Is ' + label_names).div(matrix.sum(axis=1), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual values\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted negative</th>\n",
       "      <th>Predicted positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Is negative</th>\n",
       "      <td>4730</td>\n",
       "      <td>1503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Is positive</th>\n",
       "      <td>1726</td>\n",
       "      <td>4541</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Predicted negative  Predicted positive\n",
       "Is negative                4730                1503\n",
       "Is positive                1726                4541"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# random forest\n",
    "y_true = y_test\n",
    "y_pred = rf.predict(X_test)\n",
    "matrix = confusion_matrix(y_true, y_pred)\n",
    "rf_acc = accuracy_score(y_true, y_pred)\n",
    "\n",
    "# value count\n",
    "print(\"Actual values\")\n",
    "label_names = pd.Series(['negative', 'positive'])\n",
    "pd.DataFrame(matrix,\n",
    "     columns='Predicted ' + label_names,\n",
    "     index='Is ' + label_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted negative</th>\n",
       "      <th>Predicted positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Is negative</th>\n",
       "      <td>0.758864</td>\n",
       "      <td>0.241136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Is positive</th>\n",
       "      <td>0.275411</td>\n",
       "      <td>0.724589</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Predicted negative  Predicted positive\n",
       "Is negative            0.758864            0.241136\n",
       "Is positive            0.275411            0.724589"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# percentage\n",
    "print(\"Percentage\")\n",
    "label_names = pd.Series(['negative', 'positive'])\n",
    "pd.DataFrame(matrix,\n",
    "     columns='Predicted ' + label_names,\n",
    "     index='Is ' + label_names).div(matrix.sum(axis=1), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual values\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted negative</th>\n",
       "      <th>Predicted positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Is negative</th>\n",
       "      <td>4635</td>\n",
       "      <td>1598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Is positive</th>\n",
       "      <td>1434</td>\n",
       "      <td>4833</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Predicted negative  Predicted positive\n",
       "Is negative                4635                1598\n",
       "Is positive                1434                4833"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# svc\n",
    "y_true = y_test\n",
    "y_pred = svc.predict(X_test)\n",
    "matrix = confusion_matrix(y_true, y_pred)\n",
    "svc_acc = accuracy_score(y_true, y_pred)\n",
    "\n",
    "# value count\n",
    "print(\"Actual values\")\n",
    "label_names = pd.Series(['negative', 'positive'])\n",
    "pd.DataFrame(matrix,\n",
    "     columns='Predicted ' + label_names,\n",
    "     index='Is ' + label_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted negative</th>\n",
       "      <th>Predicted positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Is negative</th>\n",
       "      <td>0.743623</td>\n",
       "      <td>0.256377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Is positive</th>\n",
       "      <td>0.228818</td>\n",
       "      <td>0.771182</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Predicted negative  Predicted positive\n",
       "Is negative            0.743623            0.256377\n",
       "Is positive            0.228818            0.771182"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# percentage\n",
    "print(\"Percentage\")\n",
    "label_names = pd.Series(['negative', 'positive'])\n",
    "pd.DataFrame(matrix,\n",
    "     columns='Predicted ' + label_names,\n",
    "     index='Is ' + label_names).div(matrix.sum(axis=1), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual values\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted negative</th>\n",
       "      <th>Predicted positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Is negative</th>\n",
       "      <td>4735</td>\n",
       "      <td>1498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Is positive</th>\n",
       "      <td>1730</td>\n",
       "      <td>4537</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Predicted negative  Predicted positive\n",
       "Is negative                4735                1498\n",
       "Is positive                1730                4537"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# naive bayes\n",
    "y_true = y_test\n",
    "y_pred = bayes.predict(X_test)\n",
    "matrix = confusion_matrix(y_true, y_pred)\n",
    "bayes_acc = accuracy_score(y_true, y_pred)\n",
    "\n",
    "# value count\n",
    "print(\"Actual values\")\n",
    "label_names = pd.Series(['negative', 'positive'])\n",
    "pd.DataFrame(matrix,\n",
    "     columns='Predicted ' + label_names,\n",
    "     index='Is ' + label_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted negative</th>\n",
       "      <th>Predicted positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Is negative</th>\n",
       "      <td>0.759666</td>\n",
       "      <td>0.240334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Is positive</th>\n",
       "      <td>0.276049</td>\n",
       "      <td>0.723951</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Predicted negative  Predicted positive\n",
       "Is negative            0.759666            0.240334\n",
       "Is positive            0.276049            0.723951"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# percentage\n",
    "print(\"Percentage\")\n",
    "label_names = pd.Series(['negative', 'positive'])\n",
    "pd.DataFrame(matrix,\n",
    "     columns='Predicted ' + label_names,\n",
    "     index='Is ' + label_names).div(matrix.sum(axis=1), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression accuracy score:  0.75592\n",
      "Random forest accuracy score:  0.74168\n",
      "SVC accuracy score:  0.75744\n",
      "Naive Bayes accuracy score:  0.74176\n"
     ]
    }
   ],
   "source": [
    "# comparing acc scores\n",
    "print(\"Logistic regression accuracy score: \", logreg_acc)\n",
    "print(\"Random forest accuracy score: \", rf_acc)\n",
    "print(\"SVC accuracy score: \", svc_acc)\n",
    "print(\"Naive Bayes accuracy score: \", bayes_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, logistic regression had the highest accuracy score, with SVC in second, Naive Bayes third, and random forest in last."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
