{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_id</th>\n",
       "      <th>source_name</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>body</th>\n",
       "      <th>date_published</th>\n",
       "      <th>language</th>\n",
       "      <th>date_modified</th>\n",
       "      <th>author_list</th>\n",
       "      <th>images</th>\n",
       "      <th>description</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>emotions</th>\n",
       "      <th>entities</th>\n",
       "      <th>quotations</th>\n",
       "      <th>prValues</th>\n",
       "      <th>clipping</th>\n",
       "      <th>label</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'5404c9d2fd24852afa122f2cc01cb3acba3c5d05b682d...</td>\n",
       "      <td>'kabargayo.com</td>\n",
       "      <td>'Kredit sepeda motor bisa terbayar jika Anda m...</td>\n",
       "      <td>'https://www.kabargayo.com/2024/09/19/kredit-s...</td>\n",
       "      <td>'Jakarta, VIVA â€“ Pembayaran kredit sepeda moto...</td>\n",
       "      <td>19/09/2024 22.32</td>\n",
       "      <td>'id</td>\n",
       "      <td>19/09/2024 22.32</td>\n",
       "      <td>'Aldi Hadad</td>\n",
       "      <td>'https://i1.wp.com/thumb.viva.co.id/media/fron...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>'positive</td>\n",
       "      <td>NaN</td>\n",
       "      <td>'Hari Pembayaran Berbayar atau Harcilnas 2024,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5250000</td>\n",
       "      <td>Adira</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'e1e3f8d68b58568e8217b7562d48de634fceb0d837135...</td>\n",
       "      <td>'viva.co.id</td>\n",
       "      <td>'Kredit Motor Bisa Lunas Jika Bayar Cicilan Te...</td>\n",
       "      <td>'https://www.viva.co.id/otomotif/tips/1753596-...</td>\n",
       "      <td>'Jakarta, VIVA â€“ Cicilan kredit motor yang ser...</td>\n",
       "      <td>19/09/2024 22.30</td>\n",
       "      <td>'id</td>\n",
       "      <td>19/09/2024 22.30</td>\n",
       "      <td>'Krisna Wicaksono</td>\n",
       "      <td>'https://thumb.viva.co.id/media/frontend/thumb...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>'positive</td>\n",
       "      <td>NaN</td>\n",
       "      <td>'Harinya Cicilan Lunas,2024,PT Adira Dinamika ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5250000</td>\n",
       "      <td>Adira</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'dca74b8fa4eabf60cebfa7b811ecb385872a0fd301eaf...</td>\n",
       "      <td>'kabarmegapolitan.pikiran-rakyat.com</td>\n",
       "      <td>'Adira Finance Umumkan Pemenang HARCILNAS 2024...</td>\n",
       "      <td>'https://kabarmegapolitan.pikiran-rakyat.com/b...</td>\n",
       "      <td>'KABARMEGAPOLITAN.com - PT Adira Dinamika Mult...</td>\n",
       "      <td>19/09/2024 21.45</td>\n",
       "      <td>'id</td>\n",
       "      <td>19/09/2024 21.45</td>\n",
       "      <td>'Yuliansyah</td>\n",
       "      <td>'https://assets.pikiran-rakyat.com/www/network...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>'positive</td>\n",
       "      <td>'HARCILNAS merupakan wujud apresiasi kami kepa...</td>\n",
       "      <td>'PT Adira Dinamika,Cicilan Lunas HARCILNAS,12 ...</td>\n",
       "      <td>(Person :Tania Endah Budhi ,Quote : HARCILNAS ...</td>\n",
       "      <td>5250000</td>\n",
       "      <td>Adira</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'56c73e2a6d254a17a5cc21dee7ed0b4660c3af70c093b...</td>\n",
       "      <td>'banggairaya.id</td>\n",
       "      <td>'Dapatkan Promo Menarik, Yamaha Prima Motor Ra...</td>\n",
       "      <td>'https://banggairaya.id/dapatkan-promo-menarik...</td>\n",
       "      <td>'BANGGAI RAYA- Yamaha Prima Motor ramaikan pam...</td>\n",
       "      <td>19/09/2024 19.45</td>\n",
       "      <td>'id</td>\n",
       "      <td>19/09/2024 19.45</td>\n",
       "      <td>'Chikal Connect</td>\n",
       "      <td>'https://i0.wp.com/banggairaya.id/wp-content/u...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>'neutral</td>\n",
       "      <td>NaN</td>\n",
       "      <td>'RAYA- Yamaha Prima Motor,Banggai Goverment Ex...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5250000</td>\n",
       "      <td>Adira</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'1cd6c6db60224b6ee5f49cd5d6c62cd2850d9f3255721...</td>\n",
       "      <td>'jakarta.tribunnews.com</td>\n",
       "      <td>'Sindikat Penipuan Leasing, Satu Bulan Ajukan ...</td>\n",
       "      <td>'https://jakarta.tribunnews.com/2024/09/19/sin...</td>\n",
       "      <td>'Laporan wartawan TribunJakarta.com Yusuf Bach...</td>\n",
       "      <td>19/09/2024 18.43</td>\n",
       "      <td>'id</td>\n",
       "      <td>19/09/2024 18.43</td>\n",
       "      <td>'Yusuf Bachtiar</td>\n",
       "      <td>'https://asset-2.tstatic.net/jakarta/foto/bank...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>'neutral</td>\n",
       "      <td>'Pelaku ini melakukan pembiayaan pembelian ken...</td>\n",
       "      <td>'Yusuf Bachtiar TRIBUNJAKARTACOM,MEDAN,SATRIA,...</td>\n",
       "      <td>(Person :Dedi ,Quote : Pelaku ini melakukan pe...</td>\n",
       "      <td>5250000</td>\n",
       "      <td>Adira</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         original_id  \\\n",
       "0  '5404c9d2fd24852afa122f2cc01cb3acba3c5d05b682d...   \n",
       "1  'e1e3f8d68b58568e8217b7562d48de634fceb0d837135...   \n",
       "2  'dca74b8fa4eabf60cebfa7b811ecb385872a0fd301eaf...   \n",
       "3  '56c73e2a6d254a17a5cc21dee7ed0b4660c3af70c093b...   \n",
       "4  '1cd6c6db60224b6ee5f49cd5d6c62cd2850d9f3255721...   \n",
       "\n",
       "                            source_name  \\\n",
       "0                        'kabargayo.com   \n",
       "1                           'viva.co.id   \n",
       "2  'kabarmegapolitan.pikiran-rakyat.com   \n",
       "3                       'banggairaya.id   \n",
       "4               'jakarta.tribunnews.com   \n",
       "\n",
       "                                               title  \\\n",
       "0  'Kredit sepeda motor bisa terbayar jika Anda m...   \n",
       "1  'Kredit Motor Bisa Lunas Jika Bayar Cicilan Te...   \n",
       "2  'Adira Finance Umumkan Pemenang HARCILNAS 2024...   \n",
       "3  'Dapatkan Promo Menarik, Yamaha Prima Motor Ra...   \n",
       "4  'Sindikat Penipuan Leasing, Satu Bulan Ajukan ...   \n",
       "\n",
       "                                                 url  \\\n",
       "0  'https://www.kabargayo.com/2024/09/19/kredit-s...   \n",
       "1  'https://www.viva.co.id/otomotif/tips/1753596-...   \n",
       "2  'https://kabarmegapolitan.pikiran-rakyat.com/b...   \n",
       "3  'https://banggairaya.id/dapatkan-promo-menarik...   \n",
       "4  'https://jakarta.tribunnews.com/2024/09/19/sin...   \n",
       "\n",
       "                                                body    date_published  \\\n",
       "0  'Jakarta, VIVA â€“ Pembayaran kredit sepeda moto...  19/09/2024 22.32   \n",
       "1  'Jakarta, VIVA â€“ Cicilan kredit motor yang ser...  19/09/2024 22.30   \n",
       "2  'KABARMEGAPOLITAN.com - PT Adira Dinamika Mult...  19/09/2024 21.45   \n",
       "3  'BANGGAI RAYA- Yamaha Prima Motor ramaikan pam...  19/09/2024 19.45   \n",
       "4  'Laporan wartawan TribunJakarta.com Yusuf Bach...  19/09/2024 18.43   \n",
       "\n",
       "  language     date_modified        author_list  \\\n",
       "0      'id  19/09/2024 22.32        'Aldi Hadad   \n",
       "1      'id  19/09/2024 22.30  'Krisna Wicaksono   \n",
       "2      'id  19/09/2024 21.45        'Yuliansyah   \n",
       "3      'id  19/09/2024 19.45    'Chikal Connect   \n",
       "4      'id  19/09/2024 18.43    'Yusuf Bachtiar   \n",
       "\n",
       "                                              images description  sentiment  \\\n",
       "0  'https://i1.wp.com/thumb.viva.co.id/media/fron...         NaN  'positive   \n",
       "1  'https://thumb.viva.co.id/media/frontend/thumb...         NaN  'positive   \n",
       "2  'https://assets.pikiran-rakyat.com/www/network...         NaN  'positive   \n",
       "3  'https://i0.wp.com/banggairaya.id/wp-content/u...         NaN   'neutral   \n",
       "4  'https://asset-2.tstatic.net/jakarta/foto/bank...         NaN   'neutral   \n",
       "\n",
       "                                            emotions  \\\n",
       "0                                                NaN   \n",
       "1                                                NaN   \n",
       "2  'HARCILNAS merupakan wujud apresiasi kami kepa...   \n",
       "3                                                NaN   \n",
       "4  'Pelaku ini melakukan pembiayaan pembelian ken...   \n",
       "\n",
       "                                            entities  \\\n",
       "0  'Hari Pembayaran Berbayar atau Harcilnas 2024,...   \n",
       "1  'Harinya Cicilan Lunas,2024,PT Adira Dinamika ...   \n",
       "2  'PT Adira Dinamika,Cicilan Lunas HARCILNAS,12 ...   \n",
       "3  'RAYA- Yamaha Prima Motor,Banggai Goverment Ex...   \n",
       "4  'Yusuf Bachtiar TRIBUNJAKARTACOM,MEDAN,SATRIA,...   \n",
       "\n",
       "                                          quotations  prValues clipping label  \\\n",
       "0                                                NaN   5250000    Adira   NaN   \n",
       "1                                                NaN   5250000    Adira   NaN   \n",
       "2  (Person :Tania Endah Budhi ,Quote : HARCILNAS ...   5250000    Adira   NaN   \n",
       "3                                                NaN   5250000    Adira   NaN   \n",
       "4  (Person :Dedi ,Quote : Pelaku ini melakukan pe...   5250000    Adira   NaN   \n",
       "\n",
       "   category  \n",
       "0       NaN  \n",
       "1       NaN  \n",
       "2       NaN  \n",
       "3       NaN  \n",
       "4       NaN  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import LongformerTokenizer, LongformerForSequenceClassification, Trainer, TrainingArguments, EarlyStoppingCallback\n",
    "from datasets import Dataset\n",
    "import torch\n",
    "\n",
    "# Re-attempt to load the dataset using semicolon as the delimiter\n",
    "df = pd.read_csv(\"adira.csv\", delimiter=';', on_bad_lines='skip')\n",
    "\n",
    "# Display the first few rows to inspect the data structure\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['positive', 'neutral', 'negative'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cleaning the sentiment labels by removing extra characters like quotes\n",
    "\n",
    "df['sentiment'] = df['sentiment'].str.strip(\"'\")\n",
    "\n",
    "# Display unique values of sentiment to verify cleaning\n",
    "\n",
    "df['sentiment'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(850, 213)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Select relevant columns for training (text and sentiment)\n",
    "df_filtered = df[['body', 'sentiment']].dropna()\n",
    "\n",
    "# Split the data into training and validation sets (80% training, 20% validation)\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    df_filtered['body'].tolist(), df_filtered['sentiment'].tolist(), test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Display the sizes of the training and validation sets\n",
    "len(train_texts), len(val_texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import LongformerTokenizer\n",
    "\n",
    "# Load the Longformer tokenizer\n",
    "tokenizer = LongformerTokenizer.from_pretrained(\"allenai/longformer-base-4096\")\n",
    "\n",
    "# Tokenize the training and validation texts\n",
    "train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=512)\n",
    "val_encodings = tokenizer(val_texts, truncation=True, padding=True, max_length=512)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mapping = {'positive': 2, 'neutral': 1, 'negative': 0}\n",
    "train_labels = [label_mapping[label] for label in train_labels]\n",
    "val_labels = [label_mapping[label] for label in val_labels]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class SentimentDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = SentimentDataset(train_encodings, train_labels)\n",
    "val_dataset = SentimentDataset(val_encodings, val_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\rache\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "  1%|          | 12/1275 [4:09:57<438:27:25, 1249.76s/it]\n",
      "  2%|â–         | 10/535 [02:02<1:44:30, 11.94s/it]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 42\u001b[0m\n\u001b[0;32m     33\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[0;32m     34\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m     35\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     38\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[EarlyStoppingCallback(early_stopping_patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)],  \u001b[38;5;66;03m# Stop early if no improvement\u001b[39;00m\n\u001b[0;32m     39\u001b[0m )\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# Evaluate the model\u001b[39;00m\n\u001b[0;32m     45\u001b[0m results \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mevaluate()\n",
      "File \u001b[1;32mc:\\Users\\rache\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\trainer.py:2052\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   2050\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[0;32m   2051\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2052\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2053\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2054\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2055\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2056\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2057\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\rache\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\trainer.py:2388\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   2385\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_begin(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[0;32m   2387\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[1;32m-> 2388\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2390\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   2391\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[0;32m   2392\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[0;32m   2393\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[0;32m   2394\u001b[0m ):\n\u001b[0;32m   2395\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[0;32m   2396\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[1;32mc:\\Users\\rache\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\trainer.py:3518\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   3516\u001b[0m         scaled_loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m   3517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 3518\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3520\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mdetach() \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mgradient_accumulation_steps\n",
      "File \u001b[1;32mc:\\Users\\rache\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\accelerate\\accelerator.py:2246\u001b[0m, in \u001b[0;36mAccelerator.backward\u001b[1;34m(self, loss, **kwargs)\u001b[0m\n\u001b[0;32m   2244\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlomo_backward(loss, learning_rate)\n\u001b[0;32m   2245\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2246\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\rache\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_tensor.py:521\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    513\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    514\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    519\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    520\u001b[0m     )\n\u001b[1;32m--> 521\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\rache\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\autograd\\__init__.py:289\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    284\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    286\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 289\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    297\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\rache\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\autograd\\graph.py:769\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    767\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    768\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 769\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    770\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    771\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    772\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    773\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from transformers import LongformerForSequenceClassification, Trainer, TrainingArguments\n",
    "import os\n",
    "\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "\n",
    "# Check if GPU is available\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load Longformer model for sequence classification\n",
    "model = LongformerForSequenceClassification.from_pretrained(\"allenai/longformer-base-4096\", num_labels=3)\n",
    "\n",
    "# Set training arguments with improvements\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    evaluation_strategy=\"epoch\",           # Evaluate at the end of each epoch\n",
    "    save_strategy=\"epoch\",                 # Save at the end of each epoch\n",
    "    per_device_train_batch_size=8,         # Increase batch size\n",
    "    per_device_eval_batch_size=8,          # Increase batch size\n",
    "    num_train_epochs=5,                    # Increase the number of training epochs\n",
    "    learning_rate=2e-5,                    # Decrease the learning rate\n",
    "    weight_decay=0.01,                     # Add weight decay for regularization\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=50,                      # Log less frequently\n",
    "    save_total_limit=2,                    # Limit the total number of saved checkpoints\n",
    "    load_best_model_at_end=True,           # Load the best model at the end of training\n",
    "    metric_for_best_model='eval_loss',     # Save based on the best eval loss\n",
    "    greater_is_better=False,               # Lower eval loss is better\n",
    "    lr_scheduler_type=\"cosine\",            # Use cosine learning rate schedule\n",
    ")\n",
    "\n",
    "# Define Trainer with early stopping\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)],  # Stop early if no improvement\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n",
    "\n",
    "# Evaluate the model\n",
    "results = trainer.evaluate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# After training, get predictions on the validation dataset\n",
    "predictions = trainer.predict(val_dataset)\n",
    "\n",
    "# Get the predicted logits\n",
    "logits = predictions.predictions\n",
    "\n",
    "# Convert logits to predicted class labels\n",
    "predicted_labels = np.argmax(logits, axis=1)\n",
    "\n",
    "# Get the true labels\n",
    "true_labels = val_labels\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
